{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                          Black Friday purchase prediction\n",
    " To predict the purchase amount of customer against various products. The dataset contains customer demographics (age, gender, marital status, city_type, stay_in_current_city), product details (product_id and product category) and Total purchase_amount from last month. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements  \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from autograd import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the dataset and data preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the dataset\n",
    "datapath = 'Data/'\n",
    "train_csv = datapath + \"train.csv\"\n",
    "test_csv = datapath +  \"test.csv\"\n",
    "#converting csv to pandas dataframe\n",
    "train_data = pd.read_csv(train_csv)\n",
    "test_data= pd.read_csv(test_csv)  \n",
    "# train_data=train_data[0:10000]\n",
    "# test_data=test_data[0:10000]\n",
    "test_user_id = np.array(test_data[\"User_ID\"])\n",
    "test_product_id = np.array(test_data[\"Product_ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00069042</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00248942</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00087842</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00085442</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000002</td>\n",
       "      <td>P00285442</td>\n",
       "      <td>M</td>\n",
       "      <td>55+</td>\n",
       "      <td>16</td>\n",
       "      <td>C</td>\n",
       "      <td>4+</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000003</td>\n",
       "      <td>P00193542</td>\n",
       "      <td>M</td>\n",
       "      <td>26-35</td>\n",
       "      <td>15</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000004</td>\n",
       "      <td>P00184942</td>\n",
       "      <td>M</td>\n",
       "      <td>46-50</td>\n",
       "      <td>7</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000004</td>\n",
       "      <td>P00346142</td>\n",
       "      <td>M</td>\n",
       "      <td>46-50</td>\n",
       "      <td>7</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000004</td>\n",
       "      <td>P0097242</td>\n",
       "      <td>M</td>\n",
       "      <td>46-50</td>\n",
       "      <td>7</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000005</td>\n",
       "      <td>P00274942</td>\n",
       "      <td>M</td>\n",
       "      <td>26-35</td>\n",
       "      <td>20</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID Product_ID Gender    Age  Occupation City_Category  \\\n",
       "0  1000001  P00069042      F   0-17          10             A   \n",
       "1  1000001  P00248942      F   0-17          10             A   \n",
       "2  1000001  P00087842      F   0-17          10             A   \n",
       "3  1000001  P00085442      F   0-17          10             A   \n",
       "4  1000002  P00285442      M    55+          16             C   \n",
       "5  1000003  P00193542      M  26-35          15             A   \n",
       "6  1000004  P00184942      M  46-50           7             B   \n",
       "7  1000004  P00346142      M  46-50           7             B   \n",
       "8  1000004   P0097242      M  46-50           7             B   \n",
       "9  1000005  P00274942      M  26-35          20             A   \n",
       "\n",
       "  Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
       "0                          2               0                   3   \n",
       "1                          2               0                   1   \n",
       "2                          2               0                  12   \n",
       "3                          2               0                  12   \n",
       "4                         4+               0                   8   \n",
       "5                          3               0                   1   \n",
       "6                          2               1                   1   \n",
       "7                          2               1                   1   \n",
       "8                          2               1                   1   \n",
       "9                          1               1                   8   \n",
       "\n",
       "   Product_Category_2  Product_Category_3  Purchase  \n",
       "0                 NaN                 NaN      8370  \n",
       "1                 6.0                14.0     15200  \n",
       "2                 NaN                 NaN      1422  \n",
       "3                14.0                 NaN      1057  \n",
       "4                 NaN                 NaN      7969  \n",
       "5                 2.0                 NaN     15227  \n",
       "6                 8.0                17.0     19215  \n",
       "7                15.0                 NaN     15854  \n",
       "8                16.0                 NaN     15686  \n",
       "9                 NaN                 NaN      7871  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#preview of data\n",
    "display(train_data[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of handling null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNull values in Training data\n",
      "User_ID                            0\n",
      "Product_ID                         0\n",
      "Gender                             0\n",
      "Age                                0\n",
      "Occupation                         0\n",
      "City_Category                      0\n",
      "Stay_In_Current_City_Years         0\n",
      "Marital_Status                     0\n",
      "Product_Category_1                 0\n",
      "Product_Category_2            173638\n",
      "Product_Category_3            383247\n",
      "Purchase                           0\n",
      "dtype: int64\n",
      "\n",
      "\tNull values in Testing data\n",
      "User_ID                            0\n",
      "Product_ID                         0\n",
      "Gender                             0\n",
      "Age                                0\n",
      "Occupation                         0\n",
      "City_Category                      0\n",
      "Stay_In_Current_City_Years         0\n",
      "Marital_Status                     0\n",
      "Product_Category_1                 0\n",
      "Product_Category_2             72344\n",
      "Product_Category_3            162562\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# checking null values in data\n",
    "train_null=train_data.isnull().sum()\n",
    "test_null=test_data.isnull().sum()\n",
    "print(\"\\tNull values in Training data\")\n",
    "print(train_null)\n",
    "print(\"\\n\\tNull values in Testing data\")\n",
    "print(test_null)\n",
    "\n",
    "#Filling the null values with mean in both training and test data\n",
    "train_data['Product_Category_2'].fillna(round(train_data['Product_Category_2'].mean()),inplace=True)\n",
    "train_data['Product_Category_3'].fillna(round(train_data['Product_Category_3'].mean()),inplace=True)\n",
    "\n",
    "test_data['Product_Category_2'].fillna(round(test_data['Product_Category_2'].mean()),inplace=True)\n",
    "test_data['Product_Category_3'].fillna(round(test_data['Product_Category_3'].mean()),inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of converting categorical to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting categorical columns into numerical values\n",
    "label=LabelEncoder()\n",
    "#Gender column\n",
    "train_gen_dumm=pd.get_dummies(train_data['Gender'],prefix='Gender',drop_first=True)\n",
    "train_data=pd.concat([train_data,train_gen_dumm],axis='columns')\n",
    "train_data.drop(['Gender'], axis=1,inplace=True)\n",
    "test_gen_dumm=pd.get_dummies(test_data['Gender'],prefix='Gender',drop_first=True)\n",
    "test_data=pd.concat([test_data,test_gen_dumm],axis='columns')\n",
    "test_data.drop(['Gender'], axis=1,inplace=True)\n",
    "\n",
    "# Age column\n",
    "train_age_encoded =pd.DataFrame(label.fit_transform(train_data['Age']))\n",
    "train_data=pd.concat([train_data,train_age_encoded],axis='columns')\n",
    "train_data.drop(['Age'], axis=1,inplace=True)\n",
    "train_data.rename(columns = {0:'Age_Encoded'}, inplace = True)\n",
    "test_age_encoded =pd.DataFrame(label.fit_transform(test_data['Age']))\n",
    "test_data=pd.concat([test_data,test_age_encoded],axis='columns')\n",
    "test_data.drop(['Age'], axis=1,inplace=True)\n",
    "test_data.rename(columns = {0:'Age_Encoded'}, inplace = True)\n",
    "\n",
    "#City column\n",
    "train_city_dumm=pd.get_dummies(train_data['City_Category'],prefix='City_Category',drop_first=True)\n",
    "train_data=pd.concat([train_data,train_city_dumm],axis='columns')\n",
    "train_data.drop(['City_Category'], axis=1,inplace=True)\n",
    "test_city_dumm=pd.get_dummies(test_data['City_Category'],prefix='City_Category',drop_first=True)\n",
    "test_data=pd.concat([test_data,test_city_dumm],axis='columns')\n",
    "test_data.drop(['City_Category'], axis=1,inplace=True)\n",
    "                     \n",
    "#Stay_In_Current_City_Years column\n",
    "train_stay_encoded =pd.DataFrame(label.fit_transform(train_data['Stay_In_Current_City_Years']))\n",
    "train_data=pd.concat([train_data,train_stay_encoded],axis='columns')\n",
    "train_data.drop(['Stay_In_Current_City_Years'], axis=1,inplace=True)\n",
    "train_data.rename(columns = {0:'Stay_In_Current_City_Encoded'}, inplace = True)\n",
    "test_stay_encoded =pd.DataFrame(label.fit_transform(test_data['Stay_In_Current_City_Years']))\n",
    "test_data=pd.concat([test_data,test_stay_encoded],axis='columns')\n",
    "test_data.drop(['Stay_In_Current_City_Years'], axis=1,inplace=True) \n",
    "test_data.rename(columns = {0:'Stay_In_Current_City_Encoded'}, inplace = True)\n",
    "\n",
    "#combining user and product id before converting to numerical value\n",
    "for col_name in [\"User_ID\", \"Product_ID\"]:\n",
    "    combined_data = pd.concat((train_data[col_name],test_data[col_name]),axis=0)\n",
    "    label.fit(combined_data)\n",
    "    train_data[col_name] =pd.DataFrame(label.transform(train_data[col_name]))\n",
    "    test_data[col_name] =pd.DataFrame(label.transform(test_data[col_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting new features from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting new features from the dataset and adding back to the dataframe\n",
    "\n",
    "#To get purchase summary from training data to fit into testing data\n",
    "def get_purchase_values(col_name):\n",
    "    min_purchase=[]\n",
    "    max_purchase=[]\n",
    "    mean_purchase=[]\n",
    "    purchase_min = train_data.groupby(col_name)['Purchase'].min()\n",
    "    purchase_max = train_data.groupby(col_name)['Purchase'].max()\n",
    "    purchase_mean = train_data.groupby(col_name)['Purchase'].mean()\n",
    "    for row_index,row in test_data.iterrows():\n",
    "        value = row[col_name]\n",
    "        min_purchase.append(purchase_min.get(value,0))\n",
    "        max_purchase.append(purchase_max.get(value,0))\n",
    "        mean_purchase.append(purchase_mean.get(value,0))\n",
    "    return min_purchase,max_purchase,mean_purchase\n",
    "\n",
    "#To get record count from training data to fit into testing data\n",
    "def get_rowcount(col_name):\n",
    "    record_count=[]\n",
    "    train_count = train_data.groupby(col_name)[col_name].count()\n",
    "    for row_index,row in test_data.iterrows():\n",
    "        value = row[col_name]\n",
    "        record_count.append(train_count.get(value,0))\n",
    "    return record_count\n",
    "\n",
    "#Number of rows per age group\n",
    "train_data['Age_Cnt'] = train_data.groupby('Age_Encoded')['Age_Encoded'].transform('count')\n",
    "test_data['Age_Cnt'] = get_rowcount('Age_Encoded')\n",
    "\n",
    "#Number of rows per gender\n",
    "train_data['Gender_Cnt'] = train_data.groupby('Gender_M')['Gender_M'].transform('count')\n",
    "test_data['Gender_Cnt'] = get_rowcount('Gender_M')\n",
    "\n",
    "#Number of rows per Marital status\n",
    "train_data['Marital_Cnt'] = train_data.groupby('Marital_Status')['Marital_Status'].transform('count')\n",
    "test_data['Marital_Cnt'] = get_rowcount('Marital_Status')\n",
    "\n",
    "#Number of rows per Occupation group\n",
    "train_data['Occupation_Cnt'] = train_data.groupby('Occupation')['Occupation'].transform('count')\n",
    "test_data['Occupation_Cnt'] = get_rowcount('Occupation')\n",
    "\n",
    "#Number of rows per Stay_In_Current_City group\n",
    "train_data['Stay_In_Current_City_Cnt'] = train_data.groupby('Stay_In_Current_City_Encoded')['Stay_In_Current_City_Encoded'].transform('count')\n",
    "test_data['Stay_In_Current_City_Cnt'] = get_rowcount('Stay_In_Current_City_Encoded')\n",
    "\n",
    "#Number of rows per City_Category group\n",
    "train_data['City_Category_Cnt'] = train_data.groupby(['City_Category_B','City_Category_C'])['City_Category_B'].transform('count')\n",
    "test_data['City_Category_Cnt'] = get_rowcount(['City_Category_B','City_Category_C'])\n",
    "\n",
    "#Number of rows per Product_Category_1 group\n",
    "train_data['Product_Category_1_Cnt'] = train_data.groupby('Product_Category_1')['Product_Category_1'].transform('count')\n",
    "test_data['Product_Category_1_Cnt'] = get_rowcount('Product_Category_1')\n",
    "\n",
    "#Number of rows per Product_Category_2 group\n",
    "train_data['Product_Category_2_Cnt'] = train_data.groupby('Product_Category_2')['Product_Category_2'].transform('count')\n",
    "test_data['Product_Category_2_Cnt'] = get_rowcount('Product_Category_2')\n",
    "\n",
    "#Number of rows per Product_Category_3 group\n",
    "train_data['Product_Category_3_Cnt'] = train_data.groupby('Product_Category_3')['Product_Category_3'].transform('count')\n",
    "test_data['Product_Category_3_Cnt'] = get_rowcount('Product_Category_3')\n",
    "\n",
    "#Number of rows per User_ID group\n",
    "train_data['User_ID_Cnt'] = train_data.groupby('User_ID')['User_ID'].transform('count')\n",
    "test_data['User_ID_Cnt'] = get_rowcount('User_ID')\n",
    "\n",
    "#Number of rows per Product_ID group\n",
    "train_data['Product_ID_Cnt'] = train_data.groupby('Product_ID')['Product_ID'].transform('count')\n",
    "test_data['Product_ID_Cnt'] = get_rowcount('Product_ID')\n",
    "\n",
    "#Min purchase price per Product_ID \n",
    "train_data['Product_min_price'] = train_data.groupby('Product_ID')['Purchase'].transform('min')\n",
    "\n",
    "#Max purchase price per Product_ID \n",
    "train_data['Product_max_price'] = train_data.groupby('Product_ID')['Purchase'].transform('max')\n",
    "\n",
    "#Mean purchase price per Product_ID \n",
    "train_data['Product_mean_price'] = train_data.groupby('Product_ID')['Purchase'].transform('mean')\n",
    "\n",
    "#Min purchase price per User_ID \n",
    "train_data['User_min_price'] = train_data.groupby('User_ID')['Purchase'].transform('min')\n",
    "\n",
    "#Max purchase price per User_ID \n",
    "train_data['User_max_price'] = train_data.groupby('User_ID')['Purchase'].transform('max')\n",
    "\n",
    "#Mean purchase price per User_ID \n",
    "train_data['User_mean_price'] = train_data.groupby('User_ID')['Purchase'].transform('mean')\n",
    "\n",
    "test_data['Product_min_price'],test_data['Product_max_price'],test_data['Product_mean_price']=get_purchase_values('Product_ID')\n",
    "test_data['User_min_price'],test_data['User_max_price'],test_data['User_mean_price']=get_purchase_values('User_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input and output columns\n",
    "train_y = np.array(train_data[\"Purchase\"])\n",
    "train_data.drop([\"Purchase\"], axis=1, inplace=True)\n",
    "train_x = np.array(train_data).astype('float')\n",
    "test_x = np.array(test_data).astype('float')\n",
    "\n",
    "#splitting training data into train/validation dataset\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First XGB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a XGB model - 1st\n",
    "params = {}\n",
    "params[\"objective\"] = \"reg:linear\"\n",
    "params[\"eta\"] = 0.05\n",
    "params[\"min_child_weight\"] = 10\n",
    "params[\"subsample\"] = 0.8\n",
    "params[\"colsample_bytree\"] = 0.7\n",
    "params[\"scale_pos_weight\"] = 0.8\n",
    "params[\"silent\"] = 1\n",
    "params[\"max_depth\"] = 10\n",
    "params[\"early_stopping_rounds\"] = 10\n",
    "params[\"seed\"] = 0\n",
    "num_rounds = 1000\n",
    "par_list_1 = list(params.items())\n",
    "\n",
    "xgb_train_1=xgb.DMatrix(data=train_x,label=train_y)\n",
    "model_1=xgb.train(par_list_1, xgb_train_1, num_rounds)\n",
    "#predicting y label for validation dataset\n",
    "xgb_val_1=xgb.DMatrix(val_x)\n",
    "y_val_1=model_1.predict(xgb_val_1)\n",
    "#predicting y label for test dataset\n",
    "xgb_test_1=xgb.DMatrix(test_x)\n",
    "y_pred_1=model_1.predict(xgb_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second XGB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a XGB model - 2nd \n",
    "params = {}\n",
    "params[\"objective\"] = \"reg:linear\"\n",
    "params[\"eta\"] = 0.05\n",
    "params[\"min_child_weight\"] = 10\n",
    "params[\"subsample\"] = 0.8\n",
    "params[\"colsample_bytree\"] = 0.7\n",
    "params[\"scale_pos_weight\"] = 0.8\n",
    "params[\"silent\"] = 1\n",
    "params[\"max_depth\"] = 10\n",
    "params[\"early_stopping_rounds\"] = 10\n",
    "params[\"seed\"] = 100\n",
    "num_rounds = 1500\n",
    "par_list_2 = list(params.items())\n",
    "\n",
    "xgb_train_2=xgb.DMatrix(data=train_x,label=train_y)\n",
    "model_2=xgb.train(par_list_2, xgb_train_2, num_rounds)\n",
    "#predicting y label for validation dataset\n",
    "xgb_val_2=xgb.DMatrix(val_x)\n",
    "y_val_2=model_2.predict(xgb_val_2)\n",
    "#predicting y label for test dataset\n",
    "xgb_test_2=xgb.DMatrix(test_x)\n",
    "y_pred_2=model_2.predict(xgb_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSE score of validation dataset by taking average of 2 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE score of validation dataset is :2394.438411752429\n"
     ]
    }
   ],
   "source": [
    "#Taking average of 2 models for validation dataset prediction and calculatin RMSE score\n",
    "y_val=(y_val_1+y_val_2)/2\n",
    "y_diff=val_y-y_val\n",
    "RMSE=(((np.sum(y_diff**2))/y_diff.size)**0.5)\n",
    "print(f\"The RMSE score of validation dataset is :{RMSE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSE score of Test dataset by taking average of 2 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking average of 2 models for test dataset prediction\n",
    "final_data = pd.DataFrame({\"User_ID\":test_user_id})\n",
    "final_data[\"Product_ID\"] = test_product_id\n",
    "final_data[\"Purchase\"] =(y_pred_1+y_pred_2)/2\n",
    "final_data.to_csv(\"black_friday_pred.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The RMSE score for the test data by submitting in contest is 2467"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
